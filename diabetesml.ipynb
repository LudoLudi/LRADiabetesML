{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION ALGORITHM\n",
    "#  ----------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "x = data.drop('Outcome', axis=1)  # All columns except 'Outcome'\n",
    "y = data['Outcome']  # Only the 'Outcome' column\n",
    "# print(x)\n",
    "# print(y)\n",
    "\n",
    "# Split the data into training and test sets. Configure test-size to change which percentage of data is used for testing\n",
    "# Random_state to control the randomness resulting from the split. Algorithm can work without it but expect inconsistent outputs\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=51)\n",
    "\n",
    "# Standardize the features (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)  # Fit and transform the training data\n",
    "x_test = scaler.transform(x_test)  # Only transform the test data\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# Print classification report\n",
    "print(\"1. Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Graph the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('2. Confusion Matrix')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "# Print ROC AUC score\n",
    "print(\"3. ROC AUC Score:\\n\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------\n",
    "The algorithm primarily utilizes functions from the sklearn library.\n",
    "\n",
    "The dataset is first loaded via pandas, where the features and outcome column are seperated into the variables x and y respectively. The data is then split into two; the test_size variable determines the percentage used for training, whilst the remainder goes towards training. The value of the random_state will help with the resulting randomness from the split; and for further consistency we standardize the features with StandardScaler().\n",
    "\n",
    "The algorithm is then initiated. The model is trained with the training data, and predictions are made on the test features. The resulting data is then evaluated via comparison to y_test (the actual target values); the final results are then printed.\n",
    "\n",
    "In summary, features are the inputs the model uses to learn patterns; and the target is the output the model aims to predict.\n",
    "\n",
    "There are three outputs.\n",
    "\n",
    "\n",
    "1. Classification Report\n",
    "Provides a breakdown of the two classes: tested negative (0), and tested positive (1) for diabetes.\n",
    "\n",
    "First, The report outputs four factors:\n",
    "1a. Precision == The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "1b. Recall == The ratio of correctly predicted positive observations to all the observations in the actual class.\n",
    "1c. F1-Score == The weighted average of Precision and Recall.\n",
    "1d. Support == The number of actual occurrences of the class in the dataset.\n",
    "\n",
    "Second, the accuraccy; the proportion of correctly predicted instances out of the total number of instances.\n",
    "\n",
    "\n",
    "2. Confusion Matrix\n",
    "Shows the number of correct and incorrect predictions the model made for each class. The ouput is a 2x2 matrix.\n",
    "\n",
    "\n",
    "3. ROC AUC Score\n",
    "The ROC (Receiver Operating Characteristic) AUC (Area Under the Curve) score is a performance measurement for classification problems at various threshold settings. It is a measure of how much the model is capable of distinguishing between classes. A score of 0.7 and above means the algorithm is working within an acceptable range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
